{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smaller-barrier",
   "metadata": {},
   "source": [
    "# 10-1. ë“¤ì–´ê°€ë©°\n",
    "ë‚˜ë¦„ëŒ€ë¡œ í˜ì‹ ì ì´ì—ˆë˜ Sequence-to-Sequence êµ¬ì¡°ë¡œ ë²ˆì—­ê¸°ë¥¼ ë§Œë“¤ì—ˆìœ¼ë‚˜ ì„±ëŠ¥ì´ ê¸°ëŒ€ì— ë¯¸ì¹˜ì§€ ì•Šì•„ ì‹¤ë§í•˜ì‹  ë¶„ë„ ê³„ì‹ ê°€ìš”? ì˜ˆë¬¸ í•œë‘ ê°œ ë¹¼ê³ ëŠ” ê±°ì˜ ë‹¤ ì´ìƒí•œ ë²ˆì—­ë¬¸ë§Œ ë‚˜ì™€ì„œ ìŠ¬íë˜ ê¸°ì–µì´ ìˆìœ¼ì‹œë”ë¼ë„â€¦ğŸ˜¢ í•˜ì§€ë§Œ ì´ë²ˆì—” ë‹¤ë¥¼ ê±°ì˜ˆìš”!\n",
    "    \n",
    "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” í˜„ì¬ê¹Œì§€ë„ ê°ì¢… ë²ˆì—­ ë¶€ë¬¸ì—ì„œ ìµœê³ ì˜ ì„±ëŠ¥ì„ ìë‘í•˜ëŠ” ëª¨ë¸ì´ë‹ˆ ì´ë²ˆì—ì•¼ë§ë¡œ ì •ë§ ë©‹ì§„ ë²ˆì—­ê¸°ë¥¼ ë§Œë“¤ì–´ ë³´ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”. ê²Œë‹¤ê°€ ì´ì „ ê°•ì˜ ë…¸ë“œì—ì„œ ë°°ì› ë˜ ì‹ ì„ í•œ ê°œë…ë“¤ì´ ì–´ë–»ê²Œ êµ¬í˜„ì´ ë ì§€ ê¶ê¸ˆí•˜ì§€ ì•Šë‚˜ìš”? íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ì•ìœ¼ë¡œë„ NLP ë¶„ì•¼ì—ì„œëŠ” ì–´ëŠ ê³³ì—ë„ ë¹ ì§€ì§€ ì•ŠëŠ” ê°€ì¥ ì¤‘ìš”í•œ ëª¨ë¸êµ¬ì¡°ì˜ ê·¼ê°„ì´ ë˜ê¸° ë•Œë¬¸ì—, ì˜¤ëŠ˜ êµ¬í˜„ ì‹¤ìŠµì„ í†µí•´ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ë¥¼ ê¼¼ê¼¼ì´ íŒŒì•…í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "### ì¤€ë¹„ë¬¼\n",
    "í„°ë¯¸ë„ì„ ì—´ê³  í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n",
    "```\n",
    "$ mkdir -p ~/aiffel/transformer\n",
    "```\n",
    "ì‹¤ìŠµì—ì„œëŠ” í•œêµ­ì–´ê°€ í¬í•¨ëœ ë§ë­‰ì¹˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, í•œêµ­ì–´ë¥¼ ì˜ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ë§Œ matplotlib ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê¸°ë³¸ í°íŠ¸ëŠ” í•œêµ­ì–´ë¥¼ ì§€ì›í•˜ì§€ ì•Šì•„ìš”! ì˜¬ë°”ë¥¸ Attention Mapì„ í™•ì¸í•˜ê¸° ìœ„í•´ í•œêµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” í°íŠ¸ë¡œ ë³€ê²½í•´ ì£¼ë„ë¡ í•©ì‹œë‹¤.\n",
    "    \n",
    "ì•„ì§ ì»´í“¨í„°ì— ê¸€ê¼´ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´, í„°ë¯¸ë„ì—ì„œ ë‚˜ëˆ” ê¸€ê¼´ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "```\n",
    "$ sudo apt -qq -y install fonts-nanum\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-episode",
   "metadata": {},
   "source": [
    "# 10-2. ë‚´ë¶€ ëª¨ë“ˆ êµ¬í˜„í•˜ê¸°\n",
    "ì´ë²ˆ ì½”ìŠ¤ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì™„ì„±í•˜ëŠ” ë°ì— í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ í•˜ë‚˜í•˜ë‚˜ ë§Œë“  í›„, ì¡°ë¦½í•˜ì—¬ ì™„ì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•  ê²ë‹ˆë‹¤.\n",
    "    \n",
    "ì, Tensorë¡œ ë³€í™˜í•œ ì…ë ¥ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•˜ê³  íë¦„ì„ ìƒê°í•´ë´…ì‹œë‹¤. ìµœì´ˆì˜ í…ìŠ¤íŠ¸ ì…ë ¥ ë°ì´í„°ëŠ” [ batch_size x length ] ì˜ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆê² ì£ ? ë²ˆì—­ì´ ëë‚˜ê³  ë‚œ ìµœì¢… ì¶œë ¥ ë°ì´í„°ëŠ” [ batch_size x length x vocab_size ]ì˜ í˜•íƒœë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. ë²ˆì—­ ë¬¸ì œëŠ” ê²°êµ­ ë§¤ ìŠ¤í…ë§ˆë‹¤ vocab_size ë§Œí¼ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ ì¤‘ì— ì ë‹¹í•œ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ì‘ì—…ì„ lengthë§Œí¼ ë°˜ë³µí•˜ëŠ” ê²ƒì´ë‹ˆê¹Œìš”. ëª¨ë¸ êµ¬ì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ë ˆì´ì–´ë¥¼ í†µê³¼í•  ë•Œë§ˆë‹¤ í…ì„œì˜ shapeê°€ ì–´ë–»ê²Œ ë°”ë€ŒëŠ”ì§€ë¥¼ ëˆˆì—¬ê²¨ ë´…ì‹œë‹¤.    \n",
    "\n",
    "1. ì…ë ¥ ë°ì´í„° â†’ [ batch_size x length ]\n",
    "2. Source & Target Embedding â†’ [ batch_size x length x d_emb ]\n",
    "3. Positional Encoding ê°•ì˜ ë…¸ë“œì—ì„œ êµ¬í˜„ì„ í–ˆì—ˆì£ ? 2ë²ˆì˜ ê²°ê³¼ì— ë”í•´ì§€ë¯€ë¡œ shape ë³€í™”ëŠ” ì—†ìŠµë‹ˆë‹¤.\n",
    "4. Multi-Head Attention ì•„ë˜ì™€ ê°™ì´ ì—¬ëŸ¬ ê°œì˜ ì„œë¸Œ ëª¨ë“ˆë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "    1. Split Heads â†’ [ batch_size x length x heads x (d_emb / n_heads) ]\n",
    "    2. Masking for Masked Attention\n",
    "    3. Scaled Dot Product Attention\n",
    "    4. Combine Heads â†’[ batch_size x length x d_emb ]\n",
    "5. Residual Connection\n",
    "6. Layer Normalization\n",
    "7. Position-wise Feed-Forward Network â†’ [ batch_size x length x d_ff ]\n",
    "8. Output Linear Layer â†’ [ batch_size x length x vocab_size ]    \n",
    "\n",
    "ì™€â€¦ ì •ë§ ë§ë„¤ìš”â€¦ ê·¸ë˜ë„ êµµê²Œ í‘œì‹œëœ ëª¨ë“ˆì„ ì œì™¸í•˜ë©´ ë‚˜ë¨¸ì§€ëŠ” í…ì„œí”Œë¡œìš° ë‚´ë¶€ì— ì´ë¯¸ êµ¬í˜„ì²´ê°€ í¬í•¨ë˜ì–´ ìˆì–´ì„œ ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹µë‹ˆë‹¤! ê²Œë‹¤ê°€ ì°¨ê·¼ì°¨ê·¼ ì´í•´í•´ë‚˜ê°€ë©´ í•˜ë‚˜ë„ ì–´ë µì§€ ì•Šì€ ë‚´ìš©ë“¤ì´ì˜ˆìš”. Positional Encodingë¶€í„° ì‹œì‘í•´ë³´ì£ !\n",
    "    \n",
    "ì—¬ëŠ ë•Œì²˜ëŸ¼ í”„ë¡œì íŠ¸ì— ì‚¬ìš©ë  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¨¼ì € import í•´ì£¼ì„¸ìš”.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olive-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention ì‹œê°í™”ë¥¼ ìœ„í•´ í•„ìš”!\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-suicide",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "![image](https://user-images.githubusercontent.com/69677950/115481614-f46cfc80-a287-11eb-8263-a7c0389a52aa.png)    \n",
    "ê°€ì¥ ë¨¼ì € êµ¬í˜„í•  Positional Encodingì€ ë‹¤í–‰íˆë„ ì´ì „ ê°•ì˜ ë…¸ë“œì—ì„œ êµ¬í˜„í•´ ë³¸ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤! ì†ŒìŠ¤ë¥¼ ë¹Œë ¤ì˜¤ë©´,    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unusual-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "print(\"ìŠ=3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-reservoir",
   "metadata": {},
   "source": [
    "ì´ë ‡ê²Œ ìƒê²¼ì—ˆì£ ! ê°€ê¸‰ì ì´ë©´ ì´ ì†ŒìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì—¬ëŸ¬ë¶„ì—ê²Œë„ ì¢‹ê² ì£  ^_^? ì´ ì†ŒìŠ¤ëŠ” ê±´ë“¤ì§€ ì•Šë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ, Multi-Head Attentionìœ¼ë¡œ!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-allocation",
   "metadata": {},
   "source": [
    "## Multi-Head Attention\n",
    "![image](https://user-images.githubusercontent.com/69677950/115481717-2e3e0300-a288-11eb-946a-9c17cc4cae81.png)    \n",
    "Multi-Head Attentionì€ ì—¬ëŸ¬ ê°œì˜ ì„œë¸Œ ëª¨ë“ˆì„ ê²°í•©í•˜ì—¬ ì™„ì„±ë©ë‹ˆë‹¤. Embeddingëœ ì…ë ¥ì„ Head ìˆ˜ë¡œ ë¶„í• í•˜ëŠ” split_heads(), ë¶„í• ëœ ì…ë ¥ìœ¼ë¡œë¶€í„° Attention ê°’ì„ êµ¬í•˜ëŠ” scaled_dot_product_attention(), ì—°ì‚°ì´ ì¢…ë£Œë˜ê³  ë¶„í• ëœ Headë¥¼ ë‹¤ì‹œ í•˜ë‚˜ë¡œ ê²°í•©ì‹œì¼œì£¼ëŠ” combine_heads() ê¹Œì§€ MultiHeadAttention í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ì—¬ ëª¨ë‘ í¬í•¨ì‹œì¼œì¤„ ê±°ì˜ˆìš”!\n",
    "    \n",
    "ë­”ê°€ ë¹ ì§„ ê²ƒ ê°™ë‹¤ë©´ ê·¸ê²ƒì€ ë°”ë¡œ Masking ë¶€ë¶„! ë§ˆìŠ¤í¬ì˜ í˜•íƒœë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´ ëª¨ë¸ ì™¸ë¶€ì˜ í›ˆë ¨ ë°ì´í„°ê¸° ë•Œë¬¸ì— ê·¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ëŠ” MultiHeadAttention ì™¸ë¶€ì— ì •ì˜ë˜ëŠ” ê²ƒì´ ì˜¬ë°”ë¥´ê² ì£ ! ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ëŠ” ëª¨ë¸ì„ ì™„ì„±í•œ í›„ì— êµ¬í˜„í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ëŒ€ì‹  ìƒì„±ëœ ë§ˆìŠ¤í¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ scaled_dot_product_attention() ì—ëŠ” ì•„ë˜ í•œ ì¤„ì„ í¬í•¨í•˜ì„¸ìš”!    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "joined-joyce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6c1515472f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# scaled_qk: Attentionì„ ìœ„í•œ Softmax ì§ì „ì˜ Scaled QK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscaled_qk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "# scaled_qk: Attentionì„ ìœ„í•œ Softmax ì§ì „ì˜ Scaled QK\n",
    "\n",
    "if mask is not None: scaled_qk += (mask * -1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "material-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-blake",
   "metadata": {},
   "source": [
    "ìŒâ€¦ ì‰½ì§€ ì•Šì£ ? ì €ëŠ” Multi-Head Attentionì„ ì²˜ìŒ êµ¬í˜„í•  ì ì— Headë¥¼ ë‚˜ëˆˆë‹¤ëŠ” ê°œë…ì´ ë„ˆë¬´ í—·ê°ˆë ¤ì„œ ë°˜ë³µë¬¸ì„ ëŒë©° [idx : idx + self.depth] ë¡œ ì¸ë±ì‹±í•´ì„œ ì²˜ë¦¬ë¥¼ í–ˆë˜ ê¸°ì–µì´ ìˆë‹µë‹ˆë‹¤â€¦ ì´ë ‡ê²Œ í•˜ë©´ ì—°ì‚°í•˜ëŠ” ë° ì˜¤ì¡° ì˜¤ì–µ ë…„ ê±¸ë ¤ìš”. ğŸ˜¢ ë¶€ë”” ì—¬ëŸ¬ë¶„ì€ ê°™ì€ ì‹œí–‰ì°©ì˜¤ë¥¼ ê²ªì§€ ì•Šê¸¸ ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-jaguar",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Network\n",
    "![image](https://user-images.githubusercontent.com/69677950/115481824-60e7fb80-a288-11eb-8eb0-6d64079aedd3.png)    \n",
    "Position-wise Feed-Forward NetworkëŠ” ë…¼ë¬¸ ì„¤ëª…ì—ì„œë„ ì•„ì£¼ ê°„ëµí•˜ê²Œ ì í˜€ìˆì—ˆì£ ? êµ¬í˜„ë„ ì•„ì£¼ ì‰¬ìš´ í¸ì´ëë‹ˆë‹¤. ë°”ë¡œ í™•ì¸í•˜ì‹œì£ !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "three-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-heaven",
   "metadata": {},
   "source": [
    "d_ff ëŠ” ë…¼ë¬¸ì˜ ì„¤ëª…ëŒ€ë¡œë¼ë©´ 2048 ì¼ ê±°ê³ , d_model ì€ 512 ê² ì£ ? [ batch x length x d_model ] ì˜ ì…ë ¥ì„ ë°›ì•„ w_1 ì´ 2048ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ê³  í™œì„±í•¨ìˆ˜ ReLUë¥¼ ì ìš©í•œ í›„, ë‹¤ì‹œ w_2 ë¥¼ í†µí•´ 512ì°¨ì›ìœ¼ë¡œ ë˜ëŒë¦¬ëŠ” ê³¼ì •ê¹Œì§€! ì´ë ‡ê²Œ ì‰½ê²Œ FFN ì™„ì„±ì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-hollow",
   "metadata": {},
   "source": [
    "## 10-3. ëª¨ë“ˆ ì¡°ë¦½í•˜ê¸°\n",
    "ì—¬ê¸°ê¹Œì§€ ë‚´ë¶€ì— í¬í•¨ë  ëª¨ë“ˆë“¤ì„ ëª¨ë‘ ì™„ì„±í•˜ì…¨ìŠµë‹ˆë‹¤, ëŒ€ë‹¨í•´ìš”! ì´ ëª¨ë“  ëª¨ë“ˆë“¤ì„ ê°€ì§€ê³  íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì™„ì„±í•  ìˆ˜ ìˆëŠ”ë°, ì •í™•í•˜ê²ŒëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ Encoder í•œ ì¸µê³¼ Decoder í•œ ì¸µì„ ê°ê° ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "   \n",
    "ê·¸ëŸ¼ ì´ë§Œí¼ì˜ ì½”ë“œë¥¼ 5ë²ˆ ë” ì§œì•¼ ì—¬ì„¯ ì¸µì§œë¦¬ ë…¼ë¬¸ ì† íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì™„ì„±ë˜ë‚˜ìš”..?\n",
    "    \n",
    "ì´ëŸ° ê±±ì •ì„ í•˜ì…¨ë‹¤ë©´ ì•ˆì‹¬í•˜ì„¸ìš”, ìš°ë¦¬ëŠ” ì¡°ê¸ˆ ë” ë©‹ì§€ê³  íš¨ìœ¨ì ì¸ ë°©ë²•ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì™„ì„±í•  ê±°ë‹ˆê¹Œìš”!     \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/69677950/115481914-807f2400-a288-11eb-8951-564bff250468.png)\n",
    "    \n",
    "ê°•ì˜ ë…¸ë“œê°€ ì•„ë‹Œë° ê°‘ìê¸° í‘œ? ëœ¬ê¸ˆì—†ì§€ë§Œ <Attention Is All You Need> ë…¼ë¬¸ì— í¬í•¨ëœ ì´ í‘œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì–¼ë§ˆë‚˜ ë§ì€ ì‹¤í—˜ì„ í†µí•´ì„œ íƒ„ìƒí•œ ëª¨ë¸ì¸ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ° ì‹¤í—˜ì´ ê°€ëŠ¥í•˜ê²Œ í•˜ë ¤ë©´ ëª¨ë¸ì´ ë™ì ìœ¼ë¡œ ì™„ì„±ë  ìˆ˜ ìˆê²Œë” í•´ì•¼ í•´ìš”. ì¦‰, ë ˆì´ì–´ ìˆ˜ë¥¼ ì›í•˜ëŠ” ë§Œí¼ ìŒ“ì•„ ì‹¤í—˜ì„ ììœ ìì¬ë¡œ í•  ìˆ˜ ìˆê²Œ ëª¨ë¸ì„ ì™„ì„±í•˜ìëŠ” ê±°ì£ !\n",
    "    \n",
    "ë°©ë²•ì€ ë‹¨ìˆœí•©ë‹ˆë‹¤, ë§ˆì¹˜ í…ì„œí”Œë¡œìš°ì˜ Dense ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ë“¯ì´ EncoderLayer, DecoderLayerë¥¼ ì“¸ ìˆ˜ ìˆê²Œ tf.keras.layers.Layer í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ë ˆì´ì–´ í´ë˜ìŠ¤ë¡œ ì •ì˜í•´ ì£¼ë©´ ë¼ìš”. ì—¬ëŸ¬ë¶„ì€ ì´ë¯¸ Layer í´ë˜ìŠ¤ë¥¼ ì •ì˜í•´ë³¸ ì ì´ ìˆëŠ”ë°, ë°”ë¡œ ì§ì „ì˜ MultiHeadAttention ì´ ê·¸ë ‡ê²Œ ì •ì˜ëœ ë ˆì´ì–´ëë‹ˆë‹¤! ì´ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìš©ë²•ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì£ .    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "basic-fancy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerEncoderLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ebf3c749c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 10ê°œì˜ Encoder Layerë„ í•œ ë°©ì—!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4ebf3c749c2c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 10ê°œì˜ Encoder Layerë„ í•œ ë°©ì—!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TransformerEncoderLayer' is not defined"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "\n",
    "# 10ê°œì˜ Linear Layerë¥¼ í•œ ë°©ì—!\n",
    "linear_layers = [tf.keras.layers.Dense(30) for _ in range(N)]\n",
    "\n",
    "# 10ê°œì˜ Encoder Layerë„ í•œ ë°©ì—!\n",
    "enc_layers = [TransformerEncoderLayer(30) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-recovery",
   "metadata": {},
   "source": [
    "ë©‹ì§€ì§€ ì•Šë‚˜ìš”? í˜¹ì‹œë¼ë„ ì´ëŸ° ë™ì ì¸ ë°©ì‹ì´ ë‚¯ì„¤ë‹¤ë©´ ì§€ê¸ˆë¶€í„°ë¼ë„ ìµìˆ™í•´ì§€ì‹œê¸¸ ê°•ë ¥í•˜ê²Œ ê¶Œì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-sperm",
   "metadata": {},
   "source": [
    "## Encoder ë ˆì´ì–´ êµ¬í˜„í•˜ê¸°\n",
    "ê·¸ëŸ¼ ë³¸ê²©ì ìœ¼ë¡œ ë ˆì´ì–´ë¥¼ ë””ìì¸í•´ë³´ì£ ! ë¨¼ì € EncoderLayer êµ¬í˜„ì„ ì˜ˆì‹œë¡œ ë³´ì—¬ë“œë¦´ê²Œìš”. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ DecoderLayer ë¥¼ êµ¬í˜„í•˜ì‹œë©´ ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cheap-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-nursing",
   "metadata": {},
   "source": [
    "Transformerì˜ êµ¬í˜„ì€ ì •ë§ ë§ì€ë°, ê·¸ì¤‘ì—ì„œ Normalization Layerì˜ ìœ„ì¹˜ì— ëŒ€í•œ ë…¼ì˜ê°€ ì¢…ì¢… ë‚˜ì˜¨ë‹µë‹ˆë‹¤. ì‹¤ì œ ë…¼ë¬¸ì—ì„œëŠ” [ Input ] - [ Module ] - [ Residual ] - [ Norm ] (Module = MHA, FFN)ìœ¼ë¡œ í‘œí˜„ë˜ì–´ ìˆì§€ë§Œ ì •ì‘ Official êµ¬í˜„ì¸ êµ¬ê¸€ì˜ Tensor2Tensor ì—ì„œëŠ” [ Input ] - [ Norm ] - [ Module ] - [ Residual ] ë°©ì‹ì„ ì‚¬ìš©í–ˆì–´ìš”.\n",
    "    \n",
    "í•„ìì˜ ê²½í—˜ì— ë”°ë¥´ë©´ ë ˆì´ì–´ê°€ ë§ì•„ì§ˆìˆ˜ë¡ í›„ìê°€ ì•½ê°„ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ê¸°ì— í•„ìëŠ” ë…¼ë¬¸ ëŒ€ì‹  Official êµ¬í˜„ì„ ë”°ë¥´ê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤! ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” ì†Œê·œëª¨ë¼ì„œ í° ì°¨ì´ê°€ ë‚˜ì§€ ì•Šìœ¼ë‹ˆ ì•Œì•„ë‘ê¸°ë§Œ í•´ë„ ê´œì°®ì•„ìš”. ğŸ˜ƒ    \n",
    "    \n",
    "(ì°¸ê³ ) íŠ¸ëœìŠ¤í¬ë¨¸ì˜ Layer Normalizationì˜ ìœ„ì¹˜ì— ëŒ€í•œ ë…¼ì˜ë¥¼ ë‹¤ë£¬ On Layer Normalization in the Transformer Architectureì´ë¼ëŠ” ì œëª©ì˜ ë…¼ë¬¸ì´ 2020ë…„ ì´ˆë°˜ì— ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ëª¨ë“ˆ ì•ì— Normalization Layerë¥¼ ë‘ëŠ” pre-LN ë°©ì‹ì´ ì™œ ìœ ë¦¬í•œì§€ë¥¼ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-light",
   "metadata": {},
   "source": [
    "## Decoder ë ˆì´ì–´ êµ¬í˜„í•˜ê¸°\n",
    "ìœ„ EncoderLayer í´ë˜ìŠ¤ë¥¼ ì°¸ê³ í•˜ì—¬ DecoderLayer í´ë˜ìŠ¤ë¥¼ ì™„ì„±í•˜ì„¸ìš”!\n",
    "     \n",
    "(ì°¸ê³ : Decoderì—ì„œëŠ” ë‘ ë²ˆì˜ Attentionì´ ì§„í–‰ë˜ë‹ˆ ë°˜í™˜ë˜ëŠ” Attentionë„ ë‘ ê°œê² ì£ ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-trustee",
   "metadata": {},
   "source": [
    "EncodeLayer ì™€ DecoderLayer ë¥¼ ëª¨ë‘ ì •ì˜í–ˆìœ¼ë‹ˆ ì´ë¥¼ ì¡°ë¦½í•˜ëŠ” ê²ƒì€ ì–´ë µì§€ ì•Šê² ì£ ? ì´ë¥¼ ì´ìš©í•´ Encoderì™€ Decoder í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bigger-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "\n",
    "print(\"ìŠ=3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-tribune",
   "metadata": {},
   "source": [
    "## Transformer ì™„ì„±í•˜ê¸°\n",
    "ì •ì˜ëœ Encoder ì™€ Decoder ë¥¼ ê°€ì§€ê³  ìµœì¢…ì ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤!\n",
    "    \n",
    "ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©° ì†ŒìŠ¤ì˜ ë¹ˆì¹¸ì„ ì±„ì›Œ Transformer í´ë˜ìŠ¤ë¥¼ ì™„ì„±í•˜ì„¸ìš”!\n",
    "    \n",
    "ì¡°ê±´    \n",
    "1. shared ë³€ìˆ˜ë¥¼ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ True ì¼ ê²½ìš° Decoder Embeddingê³¼ ì¶œë ¥ì¸µ Linearì˜ Weightë¥¼ ê³µìœ í•  ìˆ˜ ìˆê²Œ í•˜ì„¸ìš”! Weightê°€ ê³µìœ ë  ê²½ìš° Embedding ê°’ì— sqrt(d_model)ì„ ê³±í•´ì¤˜ì•¼ í•˜ëŠ” ê²ƒ, ìŠì§€ ì•Šìœ¼ì…¨ì£ ? (ì°¸ê³ : tf.keras.layers.Layer.set_weights())\n",
    "2. ìš°ë¦¬ê°€ ì •ì˜í•œ positional_encoding ì˜ ë°˜í™˜ê°’ í˜•íƒœëŠ” [ Length x d_model ] ì¸ë°, ì´ë¥¼ ë”í•´ ì¤„ Embedding ê°’ í˜•íƒœê°€ [ Batch x Length x d_model ] ì´ë¼ì„œ ì—°ì‚°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •í•˜ì„¸ìš”! (ì°¸ê³ : tf.expand_dims(), np.newaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-measurement",
   "metadata": {},
   "source": [
    "## 10-4. ëª¨ë¸ ë°–ì˜ ì¡°ë ¥ìë“¤\n",
    "ì•„ê¹Œë¶€í„° ì€ê·¼í•˜ê²Œ ë§ˆìŒ í•œêµ¬ì„ì„ ì°¨ì§€í•˜ê³  ìˆë˜ Maskingì„ ì‚´í´ë³¼ ì‹œê°„ì´ ë‹¤ê°€ì™”ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  íŠ¸ëœìŠ¤í¬ë¨¸ì˜ Learning Rateê°€ ì¼ë°˜ì ì´ì§€ ì•Šë‹¤ëŠ” ê²ƒë„ ê¸°ì–µí•˜ê³  ê³„ì‹¤ ê±°ì˜ˆìš”! ì§€ê¸ˆë¶€í„°ëŠ” ëª¨ë¸ ì™¸ì ì¸ ë¶€ë¶„ì„ ì •ì˜í•´ ì£¼ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì´ë²ˆ ìŠ¤í…ì—ì„œëŠ” ë°ì´í„°ì˜ íŠ¹ì„±ì´ë‚˜ í•™ìŠµ ê³¼ì •ì— ë”°ë¼ ë‹¬ë¼ì§€ëŠ” ë¶€ë¶„ì„ ë‹¤ë£¨ê²Œ ë©ë‹ˆë‹¤.   \n",
    "\n",
    "ë¨¼ì € Maskingì…ë‹ˆë‹¤. ì´ì „ ë…¸ë“œì—ì„œ ë°°ìš´ generate_causality_mask() ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë˜ëŠ”ë°, ì•½ê°„ ì¶”ê°€í•  ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤! ì•„ë˜ êµ¬í˜„ì„ ë¨¼ì € ë³´ì‹¤ê¹Œìš”?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mounted-running",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-james",
   "metadata": {},
   "source": [
    "generate_padding_mask() ëŠ” Attentionì„ í•  ë•Œì— <PAD> í† í°ì—ë„ Attentionì„ ì£¼ëŠ” ê²ƒì„ ë°©ì§€í•´ ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì¼ì „ì— Sequence-to-Sequence ëª¨ë¸ì—ì„œ Lossì— ëŒ€í•œ Maskingì„ í•´ì¤„ ë•Œë„ ìœ„ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì§„í–‰í–ˆì£ ? í•œ ë°°ì¹˜ì˜ ë°ì´í„°ì—ì„œ <PAD> í† í°ìœ¼ë¡œ ì´ë¤„ì§„ ë¶€ë¶„ì„ ëª¨ë‘ ì°¾ì•„ë‚´ëŠ” ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ëˆˆìœ¼ë¡œ ì§ì ‘ í™•ì¸í•´ë³´ì£ !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-listing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 208,
       "width": 426
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = \\\n",
    "generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-compact",
   "metadata": {},
   "source": [
    "ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ëŠ” ê° ë°°ì¹˜ ë³„ë¡œ ë°ì´í„°ì˜ ê¼¬ë¦¬ ë¶€ë¶„ì„ Masking í•˜ëŠ” í˜•íƒœì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚¯ì„  ë¶€ë¶„ì€ ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸ì˜ Decoderê°€ ì—°ê´€ëœ ë§ˆìŠ¤í¬ì¸ë°â€¦ ì´ê²ƒì´ ë°”ë¡œ Causality Maskì™€ Padding Maskë¥¼ ê²°í•©í•œ í˜•íƒœì…ë‹ˆë‹¤! ìê¸° íšŒê·€ì ì¸ íŠ¹ì„±ì„ ì‚´ë¦¬ê¸° ìœ„í•´ Masked Multi-Head Attentionì—ì„œ ì¸ê³¼ ê´€ê³„ ë§ˆìŠ¤í‚¹ì„ í–ˆë˜ ê²ƒì„ ê¸°ì–µí•˜ì‹œì£ ? ì¸ê³¼ ê´€ê³„ë¥¼ ê°€ë¦¬ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ì§€ë§Œ Decoder ì—­ì‹œ <PAD> í† í°ì€ í”¼í•´ ê°€ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì´ëŸ° í˜•íƒœì˜ ë§ˆìŠ¤í¬ê°€ ì‚¬ìš©ëœë‹µë‹ˆë‹¤!\n",
    "    \n",
    "ë˜, íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê³ ì •ëœ Learning Rateë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì—ˆì£ ! ë…¼ë¬¸ì˜ í•´ë‹¹ ë¶€ë¶„ì„ Optimizerê¹Œì§€ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ í•œë²ˆ ì‚´í´ë´…ì‹œë‹¤. ì´ì „ ë…¸ë“œì—ì„œ Learning Rateë¥¼ numpy ë¡œ ê°„ë‹¨íˆ êµ¬í˜„ì„ í–ˆì—ˆëŠ”ë°, ì´ë²ˆì—” Tensorflow ìƒì—ì„œ ì˜ êµ¬ë™ë  ìˆ˜ ìˆë„ë¡ LearningRateSchedule í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•´ë³´ì£ !   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decreased-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-memory",
   "metadata": {},
   "source": [
    "íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì œì•ˆí•œ ìˆ˜ì‹ì´ ì•„ë‹ˆë”ë¼ë„ ê°€ë³€ì ì¸ Learning Rateë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ìœ„ì™€ ê°™ì´ êµ¬í˜„ì„ í•˜ì‹œë©´ ë©ë‹ˆë‹¤. Optimizerì™€ Schedulerë¥¼ ì—°ê²°í•˜ëŠ” ê³¼ì •ë„ ì•„ì£¼ ê°„ë‹¨í•˜ì£ ! OptimizerëŠ” ë…¼ë¬¸ì— ì •ì˜ëœ ëŒ€ë¡œ Adam Optimizerë¥¼ ì‚¬ìš©í•˜ë©° ì„¸ë¶€ íŒŒë¼ë¯¸í„°ë„ ë™ì¼í•˜ê²Œ ë§ì¶° ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-problem",
   "metadata": {},
   "source": [
    "## 10-5. í”„ë¡œì íŠ¸: ë” ë©‹ì§„ ë²ˆì—­ê¸° ë§Œë“¤ê¸°\n",
    "\n",
    "### Step 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë¡œì»¬ ìœ ì €ìš©)\n",
    "ì•„ë˜ ë§í¬ì—ì„œ korean-english-park.train.tar.gz ë¥¼ ë‹¤ìš´ë¡œë“œë°›ì•„ í•œì˜ ë³‘ë ¬ ë°ì´í„°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.\n",
    "\n",
    "* [jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1)\n",
    "ğŸ’¡ì´ì „ [ Seq2seqìœ¼ë¡œ ë²ˆì—­ê¸° ë§Œë“¤ê¸° ] ì½”ìŠ¤ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì™€ ë™ì¼í•œ ë°ì´í„°ì…ë‹ˆë‹¤!\n",
    "\n",
    "í„°ë¯¸ë„ì„ ì—´ì–´ì„œ í•˜ë‹¨ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cloudy-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-21 10:06:15--  https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
      "Resolving github.com (github.com)... 52.78.231.108\n",
      "Connecting to github.com (github.com)|52.78.231.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz [following]\n",
      "--2021-04-21 10:06:15--  https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8718893 (8.3M) [application/octet-stream]\n",
      "Saving to: â€˜korean-english-park.train.tar.gzâ€™\n",
      "\n",
      "korean-english-park 100%[===================>]   8.31M  7.00MB/s    in 1.2s    \n",
      "\n",
      "2021-04-21 10:06:17 (7.00 MB/s) - â€˜korean-english-park.train.tar.gzâ€™ saved [8718893/8718893]\n",
      "\n",
      "korean-english-park.train.en\n",
      "korean-english-park.train.ko\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/aiffel/transformer/data\n",
    "!cd ~/aiffel/transformer/data\n",
    "\n",
    "!wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "!gzip -d korean-english-park.train.tar.gz\n",
    "!tar -xvf korean-english-park.train.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-memphis",
   "metadata": {},
   "source": [
    "### Step 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (í´ë¼ìš°ë“œ ìœ ì €ìš©)\n",
    "â˜ï¸í´ë¼ìš°ë“œë¥¼ ì´ìš©ì¤‘ì´ì‹  ë¶„ì€ ìš°ì¸¡í•˜ë‹¨ì˜ Cloud shellì„ ì—´ì–´ì£¼ì„¸ìš”.\n",
    "ì•„ë˜ì™€ ê°™ì´ ê³µìœ ë””ë ‰í† ë¦¬ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ì‹¬ë³¼ë¦­ ë§í¬ë¥¼ ìƒì„±í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "provincial-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ~/data ~/aiffel/transformer/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-startup",
   "metadata": {},
   "source": [
    "### Step 2. ë°ì´í„° ì •ì œ ë° í† í°í™”\n",
    "1) set ë°ì´í„°í˜•ì´ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ í™œìš©í•´ ì¤‘ë³µëœ ë°ì´í„°ë¥¼ ì œê±°í•˜ë„ë¡ í•©ë‹ˆë‹¤. ë°ì´í„°ì˜ ë³‘ë ¬ ìŒì´ ííŠ¸ëŸ¬ì§€ì§€ ì•Šê²Œ ì£¼ì˜í•˜ì„¸ìš”! ì¤‘ë³µì„ ì œê±°í•œ ë°ì´í„°ë¥¼ cleaned_corpus ì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "laden-wings",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aiffel-dj19/aiffel/transformer/data/korean-english-park.train.ko'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-837e0548f5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcleaned_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-837e0548f5a7>\u001b[0m in \u001b[0;36mclean_corpus\u001b[0;34m(kor_path, eng_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ë°ì´í„° ì •ì œ ë° í† í°í™”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aiffel-dj19/aiffel/transformer/data/korean-english-park.train.ko'"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# ë°ì´í„° ì •ì œ ë° í† í°í™”\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-microwave",
   "metadata": {},
   "source": [
    "2) ì •ì œ í•¨ìˆ˜ë¥¼ ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ê²Œ ì •ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "ì¡°ê±´\n",
    "- ëª¨ë“  ì…ë ¥ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.\n",
    "- ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜†ì— ê³µë°±ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "- ë¬¸ì¥ ì•ë’¤ì˜ ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rubber-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    # [[YOUR CODE]]\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-things",
   "metadata": {},
   "source": [
    "3) í•œê¸€ ë§ë­‰ì¹˜ kor_corpus ì™€ ì˜ë¬¸ ë§ë­‰ì¹˜ eng_corpus ë¥¼ ê°ê° ë¶„ë¦¬í•œ í›„, ì •ì œí•˜ì—¬ í† í°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤! í† í°í™”ì—ëŠ” Sentencepieceë¥¼ í™œìš©í•˜ì„¸ìš”. ì²¨ë¶€ëœ ê³µì‹ ì‚¬ì´íŠ¸ë¥¼ ì°¸ê³ í•´ ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” generate_tokenizer() í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ ko_tokenizer ê³¼ en_tokenizer ë¥¼ ì–»ìœ¼ì„¸ìš”. en_tokenizerì—ëŠ” set_encode_extra_options(\"bos:eos\") í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ íƒ€ê²Ÿ ì…ë ¥ì´ ë¬¸ì¥ì˜ ì‹œì‘ í† í°ê³¼ ë í† í°ì„ í¬í•¨í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-broadcast",
   "metadata": {},
   "source": [
    "ì¡°ê±´\n",
    "\n",
    "- ë‹¨ì–´ ì‚¬ì „ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ ì›í•˜ëŠ” í¬ê¸°ì˜ ì‚¬ì „ì„ ì •ì˜í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. (ê¸°ë³¸: 20,000)\n",
    "- í•™ìŠµ í›„ ì €ì¥ëœ model íŒŒì¼ì„ SentencePieceProcessor() í´ë˜ìŠ¤ì— Load()í•œ í›„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- íŠ¹ìˆ˜ í† í°ì˜ ì¸ë±ìŠ¤ë¥¼ ì•„ë˜ì™€ ë™ì¼í•˜ê²Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "   * \\<PAD> : 0 / \\<BOS> : 1 / \\<EOS> : 2 / \\<UNK> : 3\n",
    "- ì°¸ê³ : [google/sentencepiece](https://github.com/google/sentencepiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "intense-fever",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-04b140dccf7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mkor_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_corpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Sentencepieceë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•œ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair.split(\"\\t\")\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-gardening",
   "metadata": {},
   "source": [
    "4) í† í¬ë‚˜ì´ì €ë¥¼ í™œìš©í•´ í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜ì¸ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ì—¬ src_corpus ì™€ tgt_corpus ë¥¼ ê°ê° êµ¬ì¶•í•˜ê³ , í…ì„œ enc_train ê³¼ dec_train ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”! (â—ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ê²½ìš° í•™ìŠµì— êµ‰ì¥íˆ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "passive-anchor",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-21-af603db8da9f>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-af603db8da9f>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook    # Process ê³¼ì •ì„ ë³´ê¸° ìœ„í•´\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜ì¸ ë¬¸ì¥ë§Œ ë‚¨ê¹ë‹ˆë‹¤. \n",
    "for idx in tqdm_notebook(range(len(kor_corpus))):\n",
    "    # [[YOUR CODE]]\n",
    "\n",
    "# íŒ¨ë”©ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-caution",
   "metadata": {},
   "source": [
    "### Step 3. ëª¨ë¸ ì„¤ê³„\n",
    "ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ í™œìš©í•´ì„œ Transformer ëª¨ë¸ì„ ì„¤ê³„í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-booth",
   "metadata": {},
   "source": [
    "### Step 4. í›ˆë ¨í•˜ê¸°\n",
    "ì•ì„œ í•„ìš”í•œ ê²ƒë“¤ì„ ëª¨ë‘ ì •ì˜í–ˆê¸° ë•Œë¬¸ì— ìš°ë¦¬ëŠ” í›ˆë ¨ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤! ì•„ë˜ ê³¼ì •ì„ ì°¨ê·¼ì°¨ê·¼ ë”°ë¼ê°€ë©° ëª¨ë¸ì„ í›ˆë ¨í•˜ê³ , ì˜ˆë¬¸ì— ëŒ€í•œ ë©‹ì§„ ë²ˆì—­ì„ ì œì¶œí•˜ì„¸ìš”!\n",
    "\n",
    "1. 2 Layerë¥¼ ê°€ì§€ëŠ” Transformerë¥¼ ì„ ì–¸í•˜ì„¸ìš”.\n",
    "    (í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ììœ ë¡­ê²Œ ì¡°ì ˆí•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "present-canada",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-676f2f05b7e2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-676f2f05b7e2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    transformer = # [[YOUR CODE]]\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "transformer = # [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-dollar",
   "metadata": {},
   "source": [
    "2. ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ Learning Rate Schedulerë¥¼ ì„ ì–¸í•˜ê³ , ì´ë¥¼ í¬í•¨í•˜ëŠ” Adam Optimizerë¥¼ ì„ ì–¸í•˜ì„¸ìš”. (Optimizerì˜ íŒŒë¼ë¯¸í„° ì—­ì‹œ ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comparative-provincial",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-b5ef882c6e14>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-b5ef882c6e14>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    learning_rate = # [[YOUR CODE]]\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "learning_rate = # [[YOUR CODE]]\n",
    "optimizer = # [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-plaintiff",
   "metadata": {},
   "source": [
    "3. Loss í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì„¸ìš”.\n",
    "Sequence-to-sequence ëª¨ë¸ì—ì„œ ì‚¬ìš©í–ˆë˜ Lossì™€ ìœ ì‚¬í•˜ë˜, Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scalingí•˜ëŠ” ê³¼ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤. (íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ëª¨ë“  ì…ë ¥ì— ëŒ€í•œ Lossë¥¼ í•œ ë²ˆì— êµ¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "infrared-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scalingí•˜ëŠ” ê³¼ì •\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-accessory",
   "metadata": {},
   "source": [
    "4. train_step í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì„¸ìš”. ì…ë ¥ ë°ì´í„°ì— ì•Œë§ì€ Maskë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ì—°ì‚°ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "thousand-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # ê³„ì‚°ëœ lossì— tf.GradientTape()ë¥¼ ì ìš©í•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # ìµœì¢…ì ìœ¼ë¡œ optimizer.apply_gradients()ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. \n",
    "    # [[YOUR CODE]]\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-pastor",
   "metadata": {},
   "source": [
    "5. í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ë§¤ Epoch ë§ˆë‹¤ ì œì‹œëœ ì˜ˆë¬¸ì— ëŒ€í•œ ë²ˆì—­ì„ ìƒì„±í•˜ê³ , ë©‹ì§„ ë²ˆì—­ì´ ìƒì„±ë˜ë©´ ê·¸ë•Œì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ìƒì„±ëœ ë²ˆì—­ì„ ì œì¶œí•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-detector",
   "metadata": {},
   "source": [
    "ì˜ˆë¬¸\n",
    "1. ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\n",
    "2. ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\n",
    "3. ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\n",
    "4. ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-algebra",
   "metadata": {},
   "source": [
    "ê²°ê³¼(output)\n",
    "Translations\n",
    "> 1. obama is the president elect .\n",
    "> 2. they are in the city .\n",
    "> 3. they don t need to be a lot of drink .\n",
    "> 4. seven other people have been killed in the attacks .\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 2\n",
    "> d_model: 512\n",
    "> n_heads: 8\n",
    "> d_ff: 2048\n",
    "> dropout: 0.3\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 4000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-concentrate",
   "metadata": {},
   "source": [
    "ë²ˆì—­ ìƒì„±ì—ëŠ” ì•„ë˜ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cultural-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention ì‹œê°í™” í•¨ìˆ˜\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()\n",
    "# ë²ˆì—­ ìƒì„± í•¨ìˆ˜\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sapphire-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²ˆì—­ ìƒì„± ë° Attention ì‹œê°í™” ê²°í•©\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-longer",
   "metadata": {},
   "source": [
    "translate() í•¨ìˆ˜ì˜ plot_attention ë³€ìˆ˜ë¥¼ True ë¡œ ì£¼ë©´ ë²ˆì—­ ê²°ê³¼ì— ëŒ€í•œ Attention Mapì„ ì‹œê°í™” í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
    "ğŸ’¡ ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ì œì‹œí•œ ì˜ˆë¬¸ì€ Seq2seqìœ¼ë¡œ ë²ˆì—­ê¸° ë§Œë“¤ê¸°ì˜ ì˜ˆë¬¸ê³¼ ë™ì¼í•©ë‹ˆë‹¤. Seq2seqê³¼ Transformerë¡œ ë§Œë“  ë‘ ë²ˆì—­ê¸°ì˜ ì„±ëŠ¥ì„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì • ë“± ë‹¤ì–‘í•œ ì—°êµ¬í•´ë³´ì‹œë©´ í•™ìŠµì— ë„ì›€ì´ ë˜ì‹¤ ê±°ì˜ˆìš”!\n",
    "    \n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ìŠµì˜ ì „ ê³¼ì •ì„ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤. êµ¬í˜„ê³¼ì •ì— ì°¸ê³ í•´ ì£¼ì„¸ìš”. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "configured-spelling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a48bf425609f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0midx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enc_train' is not defined"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\",\n",
    "            \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\",\n",
    "            \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\",\n",
    "            \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-bahrain",
   "metadata": {},
   "source": [
    "### ë£¨ë¸Œë¦­ \n",
    "ì•„ë˜ì˜ ê¸°ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "    \n",
    "|í‰ê°€ë¬¸í•­|ìƒì„¸ê¸°ì¤€|\n",
    "|-----|-----|\n",
    "| 1. ë²ˆì—­ê¸° ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì˜ ì´ë£¨ì–´ì¡Œë‹¤. | ë°ì´í„° ì •ì œ, SentencePieceë¥¼ í™œìš©í•œ í† í°í™” ë° ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ ê³¼ì •ì´ ì§€ì‹œëŒ€ë¡œ ì§„í–‰ë˜ì—ˆë‹¤.|\n",
    "| 2. Transformer ë²ˆì—­ê¸° ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ êµ¬ë™ëœë‹¤.| Transformer ëª¨ë¸ì˜ í•™ìŠµê³¼ ì¶”ë¡  ê³¼ì •ì´ ì •ìƒì ìœ¼ë¡œ ì§„í–‰ë˜ì–´, í•œ-ì˜ ë²ˆì—­ê¸°ëŠ¥ì´ ì •ìƒ ë™ì‘í•œë‹¤.|\n",
    "|3. í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì˜ë¯¸ê°€ í†µí•˜ëŠ” ìˆ˜ì¤€ì˜ ë²ˆì—­ë¬¸ì´ ìƒì„±ë˜ì—ˆë‹¤.|ì œì‹œëœ ë¬¸ì¥ì— ëŒ€í•œ ê·¸ëŸ´ë“¯í•œ ì˜ì–´ ë²ˆì—­ë¬¸ì´ ìƒì„±ë˜ë©°, ì‹œê°í™”ëœ Attention Mapìœ¼ë¡œ ê²°ê³¼ë¥¼ ë’·ë°›ì¹¨í•œë‹¤.|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
