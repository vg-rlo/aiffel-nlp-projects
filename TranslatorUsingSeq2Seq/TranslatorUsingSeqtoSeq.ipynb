{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latin-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aerial-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marine-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 118964\n",
      "Example:\n",
      ">> Go.\tVe.\n",
      ">> Wait.\tEsperen.\n",
      ">> Hug me.\tAbrázame.\n",
      ">> No way!\t¡Ni cagando!\n",
      ">> Call me.\tLlamame.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "english-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: go away !\n",
      "Spanish: <start> salga de aqu ! <end>\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for pair in raw[:num_examples]:\n",
    "    eng, spa = pair.split(\"\\t\")\n",
    "\n",
    "    enc_corpus.append(preprocess_sentence(eng))\n",
    "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
    "\n",
    "print(\"English:\", enc_corpus[100])   # go away !\n",
    "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "available-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rental-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 4931\n",
      "Spanish Vocab Size: 8893\n"
     ]
    }
   ],
   "source": [
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.2)\n",
    "\n",
    "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decimal-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bearing-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "\n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blocked-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 8893)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) # 예: len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) # 예: len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extreme-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "normal-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affiliated-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1:  78%|███████▊  | 293/375 [00:51<00:14,  5.71it/s, Loss 1.4098]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[8,4] = 4931 is not in [0, 4931)\n\t [[node encoder/embedding/embedding_lookup (defined at <ipython-input-11-3c07637d4a3b>:11) ]]\n\t [[decoder_10/embedding_1/embedding_lookup/_178]]\n  (1) Invalid argument:  indices[8,4] = 4931 is not in [0, 4931)\n\t [[node encoder/embedding/embedding_lookup (defined at <ipython-input-11-3c07637d4a3b>:11) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_33618]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoder/embedding/embedding_lookup:\n src (defined at <ipython-input-17-949f58802324>:19)\t\n encoder/embedding/embedding_lookup/17145 (defined at /home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node encoder/embedding/embedding_lookup:\n src (defined at <ipython-input-17-949f58802324>:19)\t\n encoder/embedding/embedding_lookup/17145 (defined at /home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_step -> train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-949f58802324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                 dec_tokenizer)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[8,4] = 4931 is not in [0, 4931)\n\t [[node encoder/embedding/embedding_lookup (defined at <ipython-input-11-3c07637d4a3b>:11) ]]\n\t [[decoder_10/embedding_1/embedding_lookup/_178]]\n  (1) Invalid argument:  indices[8,4] = 4931 is not in [0, 4931)\n\t [[node encoder/embedding/embedding_lookup (defined at <ipython-input-11-3c07637d4a3b>:11) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_33618]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node encoder/embedding/embedding_lookup:\n src (defined at <ipython-input-17-949f58802324>:19)\t\n encoder/embedding/embedding_lookup/17145 (defined at /home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node encoder/embedding/embedding_lookup:\n src (defined at <ipython-input-17-949f58802324>:19)\t\n encoder/embedding/embedding_lookup/17145 (defined at /home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_step -> train_step\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define eval_step\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "\n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "\n",
    "        test_loss += test_batch_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "furnished-cause",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: can i have some coffee ?\n",
      "Predicted translation: creo que est s ? <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/home/aiffel-dj19/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 608,
       "width": 601
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
